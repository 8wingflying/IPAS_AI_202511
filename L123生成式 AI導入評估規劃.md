## L123 生成式 AI導入評估規劃
- L12301 生成式 AI導入評估
- L12302 生成式 AI導入規劃
- L12303 生成式 AI風險管理
  - AI 投資 vs AI 泡沫
    - IDC：2024年全球人工智慧IT總投資規模為3159億美元 https://www.secrss.com/articles/83495
    - 主權AI 
  - AI風險與類型(Types of Risks)
    - AI發展所面臨的道德(倫理)挑戰
    - AI 幻覺 (AI Hallucination)
    - 波坦金理解|potemkin understanding(自主學習)
      - 2025年MIT、芝加哥大學、哈佛大學合著的一篇爆炸性論文
      - Potemkin Understanding in Large Language Models
      - https://arxiv.org/abs/2506.21521
  - AI 與資安(Artificial Intelligence and Cybersecurity)
    - ENISA
    - 2025.9.22 G7 Cyber Expert Group Statement on Artificial Intelligence and Cybersecurity
      - https://www.bancaditalia.it/media/notizia/publication-of-the-g7-cyber-expert-group-statement-on-artificial-intelligence-and-cybersecurity/?dotcache=refresh
      - https://www.secrss.com/articles/83573
    - 盤點2025年十大MCP漏洞：風險、案例與檢測  https://www.secrss.com/articles/83513
    - 網路安全的AI Agent革命：從工具之戰到生命級的生態博弈  https://www.secrss.com/articles/83524
    - 《歐盟AI法下AI事故報告義務指南》 https://www.secrss.com/articles/83576
    - 讓大模型合成檢查器：科研團隊挖出Linux內核90餘個長期潛伏漏洞  https://www.secrss.com/articles/83599
    - Orion：模糊測試工作流自動化通用框架 https://www.secrss.com/articles/83424
    - SecCodeBench 2.0：面向智慧編碼工具的代碼安全評測體系  https://www.secrss.com/articles/83435
    - OECD《AI事件報告共同框架》 https://www.secrss.com/articles/76202
  - 生成式AI風險管理(AI Risk Assessment)
    - 風險管理 <==> AI風險管理 <==> 生成式AI風險管理
    - 風險管理
      - NIST 風險管理框架 (RMF)
      - ISO
    - AI風險管理
    　- NIST[AI Risk Management Framework](https://www.nist.gov/itl/ai-risk-management-framework)
      - ISO
    - 生成式AI風險管理
      - NIST「人工智慧風險管理框架：生成式AI概況」（Artificial Intelligence Risk Management Framework: Generative Artificial Intelligence Profile）
        - 美國國家標準暨技術研究院（National Institute of Standard and Technology, NIST）2024年7月26日發布，補充2023年1月發布的AI風險管理框架
        - 協助組織識別生成式AI（Generative AI, GAI）可能引發的風險，並提出風險管理行動
        - https://www.nist.gov/publications/artificial-intelligence-risk-management-framework-generative-artificial-intelligence  


## 延伸閱讀:AI風險與類型(Types of Risks)
- 2025.03 [AI Risk Atlas: Taxonomy and Tooling for Navigating AI Risks and Resources](https://arxiv.org/abs/2503.05780)
- IBM AI Risk Atlas
- OWASP Top 10 for LLMs and Generative AI Apps
- [The MIT AI Risk Repository](https://airisk.mit.edu/)
- 哈佛評論(Harvard Business Review)付費文章 [4 Types of Gen AI Risk and How to Mitigate Them](https://hbr.org/2024/05/4-types-of-gen-ai-risk-and-how-to-mitigate-them) 
- 2024.06 [AI Risk Categorization Decoded (AIR 2024): From Government Regulations to Corporate Policies](https://arxiv.org/abs/2406.17864)
- https://www.zendata.dev/post/ai-risk-assessment-101-identifying-and-mitigating-risks-in-ai-systems 
- https://www.mckinsey.com/capabilities/quantumblack/our-insights/getting-to-know-and-manage-your-biggest-ai-risks

## 延伸閱讀
- 資策會_生成式AI導入指引_企業應具備的AI素養
- 人工智慧科研發展指引 - 國家科學及技術委員會全球資訊網
- 歐盟《人工智慧道德準則 | ETHICS GUIDELINES FOR TRUSTWORTHY AI 》==> 提出可信賴AI生命週期框架
  - https://www.secrss.com/articles/10224 
- 人工智慧開放性：政策制定者的入門指南(AI openness: A primer for policymakers)
  - https://www.oecd.org/en/publications/ai-openness_02f73362-en.html
  - https://www.secrss.com/articles/82365 
- https://ai.iias.sinica.edu.tw/regulations/ai-law/

## AI 治理
  - 邁向可信任的AI| AI Ethics
    - 2016、2017年，電氣和電子工程師協會先後發布AI倫理設計準則
    - 2018年 美國微軟公司提出的AI倫理準則 [負責任的AI|Responsible AI at Microsoft](https://www.microsoft.com/en-us/ai/responsible-ai)
      - 公平(Fairness)
      - 可靠與安全(Reliability and safety)
      - 隱私保障與安全(Privacy and security)
      - 透明(Transparency)
      - 責任(Accountability)
      - 多元包容(Inclusiveness)
      - 成立AI倫理道德委員會，檢視產品是否符合AI倫理準則
    - 經濟合作暨發展組織（OECD）的AI倫理準則
  - 我國
    - 行政院及所屬機關（構）使用生成式AI參考指引
    - 科技部|國家科學及技術委員會-人工智慧科研發展指引
    - https://ai.iias.sinica.edu.tw/ai-ethics-guidelines-in-taiwan/
