# 🧩 特徵工程（Feature Engineering）

特徵工程是機器學習中極為關鍵的一個步驟，主要目的在於「將原始資料轉換成模型可以有效理解與學習的特徵」。  
簡單說，它是「將資料轉化為智慧」的過程，常決定模型表現的上限。

---

## 一、特徵工程的定義

> 特徵工程是指從原始資料中**提取、選擇、轉換**出最能代表問題本質的特徵，以提升模型效能的過程。

\[
\text{Feature Engineering} = f(\text{Raw Data}) \rightarrow \text{Useful Features}
\]

---

## 二、特徵工程的主要步驟

| 步驟 | 說明 | 常用技術 / 範例 |
|------|------|----------------|
| **1. 特徵擷取（Feature Extraction）** | 從原始資料中抽取有意義的屬性 | - TF-IDF、Word2Vec<br>- PCA、FFT、統計摘要 |
| **2. 特徵轉換（Feature Transformation）** | 改變資料表示形式，使其更適合模型 | - 標準化 (Standardization)<br>- 正規化 (Normalization)<br>- Log/Box-Cox 轉換 |
| **3. 類別編碼（Categorical Encoding）** | 將文字類別轉成數值 | - One-Hot Encoding<br>- Label Encoding<br>- Target Encoding |
| **4. 缺失值處理（Missing Value Handling）** | 補齊或刪除缺漏的資料 | - 均值/眾數填補<br>- KNN Imputer<br>- 插值法 |
| **5. 特徵縮放（Feature Scaling）** | 確保特徵在相同數值範圍內 | - MinMaxScaler<br>- StandardScaler |
| **6. 特徵選擇（Feature Selection）** | 選出最具影響力的特徵 | - Filter：Chi-Square、Mutual Info<br>- Wrapper：RFE<br>- Embedded：Lasso |
| **7. 特徵生成（Feature Creation）** | 基於現有資料創造新特徵 | - 時間欄位拆分（年/月/日）<br>- 比率、差異、交互項 (Interaction terms) |

---

## 三、特徵工程的數學面向

### 1️⃣ 標準化 (Z-score normalization)
\[
x' = \frac{x - \mu}{\sigma}
\]

### 2️⃣ 正規化 (Min-Max scaling)
\[
x' = \frac{x - x_{\min}}{x_{\max} - x_{\min}}
\]

### 3️⃣ PCA 降維
\[
Z = XW \quad \text{其中 } W \text{ 為特徵向量矩陣}
\]

---

## 四、應用實例（以房價預測為例）

| 原始特徵 | 特徵工程後 | 說明 |
|------------|--------------|------|
| `Date` | `Year`, `Month` | 將日期分解以捕捉季節效應 |
| `LotArea`, `GrLivArea` | `LotArea / GrLivArea` | 比值可表示土地利用率 |
| `Neighborhood` | One-Hot Encoding | 轉換地區文字成數值 |
| `Price` | log(Price) | 對數轉換以消除偏態 |

---

## 五、特徵工程的重要性

| 面向 | 說明 |
|------|------|
| **模型效能** | 好的特徵工程可大幅提升準確率與泛化能力 |
| **可解釋性** | 幫助了解哪些因素影響預測結果 |
| **運算效率** | 降維後可減少訓練時間與過擬合風險 |

---

## 六、常用工具（Python）

| 類別 | 套件 / 方法 |
|------|--------------|
| 資料處理 | `pandas`, `numpy` |
| 類別編碼 | `sklearn.preprocessing.OneHotEncoder`, `LabelEncoder` |
| 特徵縮放 | `StandardScaler`, `MinMaxScaler`, `RobustScaler` |
| 特徵選擇 | `SelectKBest`, `RFE`, `LassoCV` |
| 降維 | `PCA`, `t-SNE`, `UMAP` |

---

## 七、簡易 Python 範例

```python
import pandas as pd
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.decomposition import PCA
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline

# 模擬資料
df = pd.DataFrame({
    'area': [100, 150, 200],
    'price': [1_000_000, 1_500_000, 2_000_000],
    'type': ['A', 'B', 'A']
})

# 定義轉換流程
num_features = ['area', 'price']
cat_features = ['type']

preprocessor = ColumnTransformer([
    ('num', StandardScaler(), num_features),
    ('cat', OneHotEncoder(), cat_features)
])

pipeline = Pipeline([
    ('preprocess', preprocessor),
    ('reduce', PCA(n_components=2))
])

result = pipeline.fit_transform(df)
print(result)
