# 神經網路_進階範例1
- 範例1.多層感知機 (MLPRegressor)進行加州房價迴歸分析(使用scikit-learn套件)

## 範例1.多層感知機 (MLPRegressor) 進行加州房價迴歸分析
```python
"""
流程：
1. 載入 California Housing 資料集
2. 切分訓練 / 測試資料
3. 標準化數據
4. 建立並訓練 MLPRegressor 模型（含 early stopping）
5. 評估 MAE、RMSE、R²
6. 視覺化預測結果與學習曲線
"""

import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import fetch_california_housing
from sklearn.model_selection import train_test_split, learning_curve
from sklearn.preprocessing import StandardScaler
from sklearn.neural_network import MLPRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.pipeline import Pipeline


# === 建立多層感知機模型 ===
def build_mlp(random_state: int = 42) -> Pipeline:
    """
    建立一個含標準化的 MLP 迴歸模型。
    hidden_layer_sizes: 隱藏層架構
    alpha: L2 正規化係數
    learning_rate: 自適應學習率避免震盪
    early_stopping: 提早停止避免過擬合
    """
    mlp = MLPRegressor(
        hidden_layer_sizes=(128, 64, 32),
        activation="relu",
        solver="adam",
        alpha=1e-3,
        learning_rate="adaptive",
        learning_rate_init=1e-3,
        max_iter=2000,
        early_stopping=True,
        n_iter_no_change=20,
        validation_fraction=0.1,
        random_state=random_state
    )

    pipe = Pipeline([
        ("scaler", StandardScaler()),
        ("mlp", mlp)
    ])
    return pipe


# === 評估指標 ===
def evaluate(y_true, y_pred):
    mae = mean_absolute_error(y_true, y_pred)
    rmse = mean_squared_error(y_true, y_pred)**0.5  # Calculate RMSE manually
    r2 = r2_score(y_true, y_pred)
    return {"MAE": mae, "RMSE": rmse, "R2": r2}


# === 視覺化預測結果 ===
def plot_results(y_true, y_pred):
    plt.figure(figsize=(6, 6))
    plt.scatter(y_true, y_pred, alpha=0.6, edgecolor='k')
    lims = [min(y_true.min(), y_pred.min()), max(y_true.max(), y_pred.max())]
    plt.plot(lims, lims, 'r--')
    plt.xlabel("True Median House Value")
    plt.ylabel("Predicted")
    plt.title("MLP Regressor - California Housing Prediction")
    plt.grid(True, linestyle="--", alpha=0.4)
    plt.tight_layout()
    plt.show()


# === 學習曲線 ===
def plot_learning_curve(estimator, X, y):
    train_sizes, train_scores, val_scores = learning_curve(
        estimator=estimator,
        X=X, y=y,
        cv=5,
        scoring="r2",
        n_jobs=-1,
        train_sizes=np.linspace(0.1, 1.0, 6),
        random_state=42
    )
    plt.figure(figsize=(7, 5))
    plt.plot(train_sizes, train_scores.mean(axis=1), 'o-', label="Training R²")
    plt.plot(train_sizes, val_scores.mean(axis=1), 'o-', label="Validation R²")
    plt.xlabel("Training Samples")
    plt.ylabel("R² Score")
    plt.title("Learning Curve (MLPRegressor - California Housing)")
    plt.legend()
    plt.grid(True, linestyle="--", alpha=0.4)
    plt.tight_layout()
    plt.show()


# === 主程式 ===
def main():
    # 1. 載入資料
    data = fetch_california_housing()
    X, y = data.data, data.target

    print(f"資料筆數: {X.shape[0]}, 特徵數: {X.shape[1]}")
    print(f"特徵名稱: {data.feature_names}\n")

    # 2. 分割訓練與測試集
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42
    )

    # 3. 模型訓練
    model = build_mlp()
    model.fit(X_train, y_train)

    # 4. 模型預測與評估
    y_pred = model.predict(X_test)
    results = evaluate(y_test, y_pred)
    print("=== 模型評估結果 ===")
    for k, v in results.items():
        print(f"{k}: {v:.4f}")

    # 5. 視覺化結果
    plot_results(y_test, y_pred)
    plot_learning_curve(model, X, y)


if __name__ == "__main__":
    main()
```
