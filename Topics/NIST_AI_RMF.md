# 🧭 NIST AI RMF 
（National Institute of Standards and Technology - Artificial Intelligence Risk Management Framework）

---

## 📘 一、框架概述（Overview）

**NIST AI RMF（2023 年 1 月發布）**  
由美國國家標準與技術研究院（NIST）提出，旨在協助組織**識別、管理與降低人工智慧（AI）相關風險**，以建立「**可信任 AI（Trustworthy AI）**」。

> 本框架為自願性採用（Voluntary Framework），可用於政府、企業、學術及研究機構。

---

## 🧩 二、框架結構（Framework Structure）

| 區塊 | 說明 |
|------|------|
| **Part 1: Foundational Information** | 定義 AI、AI 風險與可信任 AI 核心概念。 |
| **Part 2: Core** | 提供四大功能（Govern、Map、Measure、Manage）與對應實作活動。 |
| **Part 3: Profiles** | 指導組織依據目標、風險容忍度、應用場景客製化實踐。 |

---

## ⚙️ 三、四大核心功能（Core Functions）

| 功能 | 中文名稱 | 核心目的 | 主要活動舉例 |
|------|-----------|-----------|---------------|
| **1. Govern（治理）** | 建立 AI 治理與倫理結構 | 建立治理政策、倫理準則、責任分配、審查機制。 |
| **2. Map（映射）** | 理解 AI 系統與風險來源 | 分析資料、模型、用途、使用者與潛在偏誤。 |
| **3. Measure（衡量）** | 評估 AI 的可信度與風險 | 檢測可解釋性、公平性、安全性、魯棒性。 |
| **4. Manage（管理）** | 制定風險緩解與持續改進策略 | 監測系統行為、建立回饋迴圈、持續優化。 |

---

## 🧠 四、可信任 AI 七大特徵（Trustworthy AI Characteristics）

| 特徵 | 中文名稱 | 說明 |
|------|-----------|------|
| 1. **Valid and Reliable** | 有效且可靠 | 模型在設計範圍內表現穩定、一致。 |
| 2. **Safe** | 安全 | 不造成使用者或社會危害。 |
| 3. **Secure and Resilient** | 安全且具韌性 | 能抵禦攻擊、異常與誤用。 |
| 4. **Accountable and Transparent** | 可追責與透明 | AI 運作具可稽核與可理解性。 |
| 5. **Explainable and Interpretable** | 可解釋與可理解 | 使用者可理解 AI 輸入與輸出關聯。 |
| 6. **Privacy-Enhanced** | 強化隱私 | 保護個資並符合隱私保護規範。 |
| 7. **Fair with Harm Mitigation** | 公平與減害 | 減少偏見與不公平結果。 |

---

## 🧩 五、AI RMF 運作流程（Lifecycle Integration）

1. **策略階段（Govern）** → 建立治理架構與風險容忍度。  
2. **設計階段（Map）** → 確認 AI 系統用途、風險來源。  
3. **開發與測試（Measure）** → 衡量可信任性與風險程度。  
4. **部署與監控（Manage）** → 持續管理與更新模型。  
5. **再評估（Govern/Map 循環）** → 回饋改進與更新治理策略。

---

## 🏛 六、Profiles（實踐配置）

組織可依據以下面向自訂 Profile：
- 業務目標（效率、安全、法規遵循）
- 應用領域（醫療、金融、公共安全）
- 風險容忍度（低風險至高風險）
- 倫理價值觀與社會影響

> Profile 使組織能客製化 AI 風險管理實踐，強化治理落地性。

---

## 🌍 七、NIST AI RMF 與其他框架比較

| 框架 | 發布機構 | 核心焦點 | 關聯性 |
|------|------------|------------|------------|
| **NIST AI RMF** | NIST (美國) | AI 風險與可信任性管理 | 技術與治理並重 |
| **OECD AI Principles** | OECD | 倫理與人權原則 | NIST RMF 參考其理念 |
| **EU AI Act** | 歐盟 | 風險分級與合規要求 | RMF 可作為合規輔助工具 |
| **ISO/IEC 42001** | ISO | AI 管理系統標準 | 與 RMF 互補 |
| **NIST CSF** | NIST | 資安風險管理 | 架構設計類似 RMF |

---

## 📈 八、應用案例（Use Cases）

| 領域 | 應用場景 | RMF 實踐重點 |
|------|------------|----------------|
| 金融 | 信用評分、詐欺偵測 | 公平性、透明度 |
| 醫療 | 疾病預測模型 | 資料品質、安全性 |
| 政府 | 智慧監控、決策輔助 | 公共信任與問責性 |
| 教育 | 智慧教學與學習系統 | 偏誤控制與可追溯性 |

---

## 🔧 九、延伸文件與工具

- **NIST AI RMF Playbook**：官方實作工具包   https://www.nist.gov/itl/ai-risk-management-framework/nist-ai-rmf-playbook
  🔗 https://airmf.nist.gov/
- **NIST AI 100-1**：AI 系統技術定義文件  
- **NIST SP 1270**：可信任 AI 指導原則  

---

## ✅ 十、結論（Conclusion）

NIST AI RMF 是一套可操作、可量化的**AI 風險管理框架**，透過四大核心功能與七項可信任特徵，協助組織：

- 建立 **AI 治理結構（Governance）**
- 衡量 **AI 信任與風險（Trustworthiness）**
- 符合法規與倫理準則（Compliance & Ethics）
- 強化 **AI 永續與社會信任（Sustainability & Public Trust）**

---

🧩 **建議延伸閱讀：**
- NIST AI RMF Playbook  
- EU AI Act 法規對照  
- OECD AI Principles  
- ISO/IEC 42001:2023 AI 管理系統標準  

---
