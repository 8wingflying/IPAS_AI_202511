# L113 機器學習概念
- L11301 機器學習基本原理
- L11302 常見的機器學習模型

### L11301 機器學習基本原理
- 機器學習定義
- 類型  ==> 資料標籤 (Data Labeling / Data Annotation)
  - 監督式學習:  分類(辨識)   迴歸(預測)
  - 非監督式學習
  - 半監督式學習
  - 強化式學習
  - 比較分析==> 監督式學習 vs 非監督式學習
- 機器學習任務: == >  機器學習|評估指標 == > 產業應用
  - 迴歸(Regression) == >  迴歸(Regression)評估指標 
  - 分類(Tasks) == > 評估指標 
    - 二元分類(Binary)
    - 多元分類(Multi-Class)
    - 多標籤分類(Multi-label)  
  - 叢集(Cluster)
  - 降維(Dimensionality reduction)
  - 孤立子偵測|異常偵測(Outlier Detection| Anomaly Detection)
    - z 分數法（Z-Score Method）
    - IQR Method (Interquartile Range, 四分位距法)
  - 不平衡學習 (Imbalance Learning)
    - 欠採樣(Under-sampling) vs 過採樣(Over-sampling)
    - 過採樣(Over-sampling)
      - SMOTE (Synthetic Minority Oversampling Technique)
      - ADASYN(自適應合成取樣)2008
- 機器學習流程  Machine learning pipeline(管線)

### L11302 常見的機器學習模型
- 監督式學習 : 迴歸(Regression) ==>  評估指標 
  - 傳統迴歸
    - 線性迴歸(Linear Regression)
    - 多元線性迴歸(Multiple Linear Regression)
    - 多項式迴歸(Polynomial Regression)
  - 正則化迴歸
    - 嶺迴歸(Ridge Regression)(L2)
    - 套索迴歸(Lasso Regression)(L1)
    - 彈性網迴歸(Elastic Net Regression)
- 監督式學習 : 分類(Tasks) ==>  評估指標
  - 單一演算法
    - Logistic Regression(羅吉斯迴歸)
    - K-近鄰演算法(K-nearest neighbors)
    - 決策樹(Decision Tree)
    - 支援向量機 SVM (Support Vector Machine)
  - 集成學習(Ensemble Learning)
    - 集成投票分類(Ensemble Voting) ==> 軟投票(Soft voting) 硬投票(Hard voting) 加權軟投票()
    - 自助聚合法(Bootstrap Aggregation) Bagging ==> 隨機森林(Random forest)
    - 提升法(Boosting) ==> 適應提升(Adaptive Boosting, AdaBoost)  梯度提升(Gradient Boosting)
    - 堆疊法(Stacking)
    - Blending(混合集成)
- 非監督式學習 :
  - 核心關鍵:相似度(Similarity) ==>群組`內`相似度高 群組`間`相似度低 ==>  評估指標 
  - 叢集(Cluster):四大類型
  - `1`.基於`質心`的方法 ==> K-Means 叢集
  - `2`.基於`分佈`的方法 ==>高斯混合模型
  - `3`.基於`連接`的方法 ==> 階層式叢集 | 聚集叢集 |分裂叢集
  - `4`.基於`密度`的方法==> DBSCAN（基於密度的雜訊應用空間叢集） 
- 非監督式學習 : 降維(Dimensionality reduction)
  - PCA(Principal Component Analysis)主成分分析

 
